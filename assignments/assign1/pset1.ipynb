{"cells":[{"cell_type":"markdown","source":["# **0. Load Preliminary Functions**"],"metadata":{"id":"URzxYKCYrwW5"}},{"cell_type":"markdown","metadata":{"id":"saoGocoSmPjr"},"source":["# a. Import Libraries and Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsFz9_IOmQSO"},"outputs":[],"source":["import torch\n","from torchvision import datasets\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import numpy as np\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"5UDt9qORli83"},"source":["# b. MNIST Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVRCzm6jko7-"},"outputs":[],"source":["tensor_transform = transforms.ToTensor()\n","\n","batch_size = 256\n","MNIST_dataset = datasets.MNIST(root = \"./data\",\n","\t\t\t\t\t\t\t\t\ttrain = True,\n","\t\t\t\t\t\t\t\t\tdownload = True,\n","\t\t\t\t\t\t\t\t\ttransform = tensor_transform)\n","\n","MNIST_loader = torch.utils.data.DataLoader(dataset = MNIST_dataset,\n","\t\t\t\t\t\t\t   batch_size = batch_size,\n","\t\t\t\t\t\t\t\t shuffle = True)\n"]},{"cell_type":"markdown","source":["# c. Training Function"],"metadata":{"id":"FlqPb9uAZWVX"}},{"cell_type":"code","source":["from math import e\n","mse = torch.nn.MSELoss()\n","\n","def loss_func(model, x, reg_func=None, coeff=1e-3):\n","    output = model(x)\n","    err = mse(output['imgs'], x)\n","    logpx_z = -1.0 * torch.sum(err)\n","\n","    if reg_func is not None:\n","      reg = reg_func(output)\n","    else:\n","      reg = 0.0\n","\n","    return -1.0 * torch.mean(logpx_z + coeff * reg)\n","\n","def train(dataloader, model, loss_func, optimizer, epochs):\n","    losses = []\n","\n","    for epoch in tqdm(range(epochs), desc='Epochs'):\n","        running_loss = 0.0\n","        batch_progress = tqdm(dataloader, desc='Batches', leave=False)\n","\n","        for iter, (images, labels) in enumerate(batch_progress):\n","            batch_size = images.shape[0]\n","            images = images.reshape(batch_size, -1).to(device)\n","            loss = loss_func(model, images)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            avg_loss = running_loss / len(MNIST_dataset) * batch_size\n","            losses.append(loss.item())\n","\n","        tqdm.write(f'----\\nEpoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\\n')\n","\n","    return losses\n"],"metadata":{"id":"QUV53Q08ZVTB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# d. Evaluation Function"],"metadata":{"id":"7nlH6ETubTuj"}},{"cell_type":"code","source":["def plot_latent_images(model, n, digit_size=28):\n","    grid_x = np.linspace(-2, 2, n)\n","    grid_y = np.linspace(-2, 2, n)\n","\n","    image_width = digit_size * n\n","    image_height = digit_size * n\n","    image = np.zeros((image_height, image_width))\n","\n","    for i, yi in enumerate(grid_x):\n","        for j, xi in enumerate(grid_y):\n","            z = torch.tensor([[xi, yi]], dtype=torch.float32).to(device)\n","            with torch.no_grad():\n","                x_decoded = model.decode(z)\n","            digit = x_decoded.view(digit_size, digit_size).cpu().numpy()\n","            image[i * digit_size: (i + 1) * digit_size,\n","                  j * digit_size: (j + 1) * digit_size] = digit\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(image, cmap='Greys_r')\n","    plt.axis('Off')\n","    plt.show()\n","\n","\n","def eval(model):\n","    original_imgs = torch.cat([MNIST_dataset[i][0] for i in range(5)])\n","    with torch.no_grad():\n","      res = model(original_imgs.reshape(5, -1).to(device))\n","      reconstructed_imgs = res['imgs']\n","      reconstructed_imgs = reconstructed_imgs.cpu().reshape(*original_imgs.shape)\n","\n","    fig, axes = plt.subplots(5, 2, figsize=(10, 25))\n","\n","    for i in range(5):\n","        original_image = original_imgs[i].reshape(28, 28)\n","        axes[i, 0].imshow(original_image, cmap='gray')\n","        axes[i, 0].set_title(f'Original Image {i+1}')\n","        axes[i, 0].axis('off')\n","\n","        reconstructed_image = reconstructed_imgs[i].reshape(28, 28)\n","        axes[i, 1].imshow(reconstructed_image, cmap='gray')\n","        axes[i, 1].set_title(f'Reconstructed Image {i+1}')\n","        axes[i, 1].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"beLPLaqgbYLF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OLJ2GaNalOpn"},"source":["# **1. AutoEncoder (AE)**"]},{"cell_type":"markdown","source":["## a. Model\n"],"metadata":{"id":"epk8CU_8URiS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XfiE0zT9kcKN"},"outputs":[],"source":["class AE(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dims):\n","        super().__init__()\n","\n","        assert hidden_dims[-1] == 2, \"always use 2 as the latent dimension for generating a 2D image grid during evaluation\"\n","        self.encoder = torch.nn.Sequential()\n","        self.decoder = torch.nn.Sequential()\n","        ##################\n","        ### Problem 1 (a): finish the implementation for encoder and decoder\n","        ##################\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decode(encoded)\n","        return {\"imgs\": decoded}\n","\n","### Test\n","hidden_dims = [128, 64, 36, 18, 2]\n","input_dim = 256\n","test_tensor = torch.randn([1, input_dim]).to(device)\n","\n","ae_test = AE(input_dim, hidden_dims).to(device)\n","\n","with torch.no_grad():\n","  test_out = ae_test(test_tensor)\n"]},{"cell_type":"markdown","metadata":{"id":"iGPX-wPVlqjK"},"source":["## b. Loss Functions and Optimizers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cROqRxt6l0Z3"},"outputs":[],"source":["def loss_AE(model, x):\n","    reconstructed = model(x)['imgs']\n","    return mse(reconstructed, x)\n","\n","image_shape = MNIST_dataset[0][0].shape\n","input_dim = torch.prod(torch.tensor(image_shape)).item()\n","print(\"input_dim: \", input_dim)\n","\n","hidden_dims = [128, 32, 16, 2]\n","\n","ae = AE(input_dim, hidden_dims).to(device)\n","print(ae)\n","\n","optimizer_ae = torch.optim.Adam(ae.parameters(),\n","                                lr = 1e-3,\n","                                weight_decay = 1e-8)\n"]},{"cell_type":"markdown","metadata":{"id":"UKznExbpqgk-"},"source":["## c. Training\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YiFd3n3oqjiX"},"outputs":[],"source":["##################\n","### Problem 1 (b): Train AE\n","epochs = 20\n","\n","log_ae = train(MNIST_loader, ae, loss_AE, optimizer_ae, epochs)\n","##################\n"]},{"cell_type":"markdown","source":["## d. Evaluation\n"],"metadata":{"id":"nqpveE8xbxmk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuwpzcxSrRGb"},"outputs":[],"source":["##################\n","### Problem 1 (b): Evaluate AE\n","eval(ae)\n","plot_latent_images(ae, n=8)\n","##################\n"]},{"cell_type":"markdown","metadata":{"id":"znrLQMSYlZb9"},"source":["# **2. Variational  AutoEncoder (VAE)**\n","## a. Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeZBbuuolcoI"},"outputs":[],"source":["class VAE(torch.nn.Module):\n","  def __init__(self, input_dim, hidden_dims, decode_dim=-1, use_sigmoid=True):\n","      '''\n","      input_dim: The dimensionality of the input data.\n","      hidden_dims: A list of hidden dimensions for the layers of the encoder and decoder.\n","      decode_dim: (Optional) Specifies the dimensions to decode, if different from input_dim.\n","      '''\n","      super().__init__()\n","\n","      self.z_size = hidden_dims[-1] // 2\n","\n","      self.encoder = torch.nn.Sequential()\n","      self.decoder = torch.nn.Sequential()\n","      ##################\n","      ### Problem 2(b): finish the implementation for encoder and decoder\n","      ##################\n","\n","  def encode(self, x):\n","      mean, logvar = torch.split(self.encoder(x), split_size_or_sections=[self.z_size, self.z_size], dim=-1)\n","      return mean, logvar\n","\n","  def reparameterize(self, mean, logvar, n_samples_per_z=1):\n","      ##################\n","      ### Problem 2(c): finish the implementation for reparameterization\n","      ##################\n","      pass\n","\n","  def decode(self, z):\n","      probs = self.decoder(z)\n","      return probs\n","\n","  def forward(self, x, n_samples_per_z=1):\n","      mean, logvar = self.encode(x)\n","\n","      batch_size, latent_dim = mean.shape\n","      if n_samples_per_z > 1:\n","        mean = mean.unsqueeze(1).expand(batch_size, n_samples_per_z, latent_dim)\n","        logvar = logvar.unsqueeze(1).expand(batch_size, n_samples_per_z, latent_dim)\n","\n","        mean = mean.contiguous().view(batch_size * n_samples_per_z, latent_dim)\n","        logvar = logvar.contiguous().view(batch_size * n_samples_per_z, latent_dim)\n","\n","      z = self.reparameterize(mean, logvar, n_samples_per_z)\n","      x_probs = self.decode(z)\n","\n","      x_probs = x_probs.reshape(batch_size, n_samples_per_z, -1)\n","      x_probs = torch.mean(x_probs, dim=[1])\n","\n","      return {\n","          \"imgs\": x_probs,\n","          \"z\": z,\n","          \"mean\": mean,\n","          \"logvar\": logvar\n","      }\n","\n","### Test\n","hidden_dims = [128, 64, 36, 18, 18]\n","input_dim = 256\n","test_tensor = torch.randn([1, input_dim]).to(device)\n","\n","vae_test = VAE(input_dim, hidden_dims).to(device)\n","\n","with torch.no_grad():\n","  test_out = vae_test(test_tensor)\n"]},{"cell_type":"markdown","source":["## b. Loss Functions\n","\n","### Loss 1: Stoachastic Gradient Variational Bayes (SGVB) Estimator\n","\n","VAEs are trained by maximizing the Evidence Lower Bound (ELBO) on the marginal log-likelihood:\n","$$\\log p(x) \\geq \\mathbb{E}_{q(z|x)}[\\log\\frac{p(x, z)}{q(z|x)}] = \\mathrm{ELBO},$$\n","\n","where $x$ is the data (binary images for MNIST) and $z$ is the latent code.\n","\n","In practice, the above expectation is estimated using Monte Carlo sampling, yielding the generic Stoachastic Gradient Variational Bayes (SGVB) estimator,\n","$$\\mathrm{ELBO} \\approx \\sum_{i, j} [\\log p(x_i|z_{i, j}) + \\log p(z_{i, j}) - \\log q(z_{i, j}|x_i)], $$\n","where $z_{i, j}$ is sampled from $ q(z|x_i) = \\mathcal{N}(z;\\mu_i, \\sigma^2_i \\mathbf{I})$. In this assignment, we only sample one $z_{i,j}$ for each $x_i$ (see the function ``reparameterize()`` in the ``VAE()`` class)."],"metadata":{"id":"Y1uNMVp4bHVM"}},{"cell_type":"code","source":["##### Loss 1: SGVB #####\n","log2pi = torch.log(2.0 * torch.tensor(np.pi)).to(device)\n","torch_zero = torch.tensor(0.0).to(device)\n","\n","def log_normal_pdf(sample, mean, logvar, raxis=1):\n","    ##################\n","    ### Problem 2(d): finish the implementation for the log-probability for normal distribution with mean and var\n","    ##################\n","    pass\n","\n","def loss_SGVB(output):\n","    logpz = log_normal_pdf(output['z'], torch_zero, torch_zero)\n","    logqz_x = log_normal_pdf(output['z'], output['mean'], output['logvar'])\n","    return logpz -logqz_x\n"],"metadata":{"id":"Z2QMPmCSbO94"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loss 2: KL Divergence w/o Estimation\n","In many cases, Monte Carlo sampling is not necessary to estimate all the terms of ELBO, as some terms can be integrated analytically. In the assignment, you derived the cases where the ELBO can be expressed as an analytical KL-divergence plus the expected reconstruction error, specifically when both $q(z|x)$ and $p(z)$ are Gaussian distributions:\n","$$\\mathrm{ELBO} ≈ -D_{KL}(q(z|x) || p(z)) + \\sum_{i, j} \\log p(x_i|z_{i, j}) = \\\\\\frac{1}{2}\\sum_{d}(1+\\log((\\sigma_d)^2) - (\\mu_d)^2 - (\\sigma_d)^2) + \\sum_{i, j} \\log p(x_i|z_{i, j})$$"],"metadata":{"id":"MvtkFSAjt2o7"}},{"cell_type":"code","source":["##### Loss 2: KL w/o Estimation #####\n","def loss_KL_wo_E(output):\n","    var = torch.exp(output['logvar'])\n","    logvar = output['logvar']\n","    mean = output['mean']\n","\n","    return -0.5 * torch.sum(torch.pow(mean, 2)\n","                            + var - 1.0 - logvar,\n","                            dim=[1])\n"],"metadata":{"id":"R8_BR39pt20a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## c. Verifying loss 1 == loss 2\n"],"metadata":{"id":"ogJfK717tEAr"}},{"cell_type":"code","source":["##################\n","### Problem 3(b): Check if the analytical KL divergence matches the Monte Carlo estimate.\n","hidden_dims = [128, 32, 16, 4]\n","image_shape = MNIST_dataset[0][0].shape\n","input_dim = torch.prod(torch.tensor(image_shape)).item()\n","vae_test = VAE(input_dim, hidden_dims).to(device)\n","\n","all_l_sgvb, all_KL_wo_E = [], []\n","all_n_samples_per_z = list(range(1, 4000, 100))\n","\n","with torch.no_grad():\n","    for n_samples_per_z in all_n_samples_per_z:\n","        for _, (imgs, _) in enumerate(MNIST_loader):\n","            batch_size = imgs.shape[0]\n","            imgs = imgs.reshape(batch_size, -1).to(device)\n","\n","            output = vae_test(imgs, n_samples_per_z=n_samples_per_z)\n","\n","            l_sgvb = torch.mean(loss_SGVB(output))\n","            l_KL_wo_E = torch.mean(loss_KL_wo_E(output))\n","\n","            all_l_sgvb.append(l_sgvb.item())\n","            all_KL_wo_E.append(l_KL_wo_E.item())\n","            break\n","\n","# Plot the two curves\n","plt.figure(figsize=(12, 6))\n","\n","plt.plot(all_n_samples_per_z, all_l_sgvb, label='SGVB Loss')\n","plt.plot(all_n_samples_per_z, all_KL_wo_E, label='KL Divergence (w/o E)')\n","\n","plt.xlabel('Number of Samples per z')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.grid(True)\n","plt.show()\n","##################\n"],"metadata":{"id":"i8nIZuXa5Tk_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## d. Training with ELBO loss\n","\n"],"metadata":{"id":"nircBTxhitxo"}},{"cell_type":"code","source":["##################\n","### Problem 3(c): Train VAE with ELBO loss\n","epochs = 20\n","\n","hidden_dims = [128, 32, 16, 4]\n","assert hidden_dims[-1] == 4, \"always use 4 as the latent dimension for generating a 2D image grid during evaluation\"\n","\n","image_shape = MNIST_dataset[0][0].shape\n","input_dim = torch.prod(torch.tensor(image_shape)).item()\n","print(\"input_dim: \", input_dim)\n","\n","vae_sgvb = VAE(input_dim, hidden_dims).to(device)\n","print(vae_sgvb)\n","\n","coeff = 1e-3\n","\n","optimizer_vae_sgvb = torch.optim.Adam(vae_sgvb.parameters(),\n","                                lr = 1e-4,\n","                                weight_decay = 1e-8)\n","\n","log_vae_sgvb = train(MNIST_loader, vae_sgvb, lambda model, x: loss_func(model, x, reg_func=loss_SGVB, coeff=1e-3), optimizer_vae_sgvb, epochs)\n","##################\n"],"metadata":{"id":"Sub8yMlhiuLo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ytCu3s3sl0xT"},"source":["## e. Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5bSKQN3zv4m"},"outputs":[],"source":["##################\n","### Problem 3(c): Evaluate VAE with ELBO loss\n","eval(vae_sgvb)\n","plot_latent_images(vae_sgvb, n=8)\n","##################\n"]},{"cell_type":"markdown","source":["## f. Training with KL Divergence w/o Estimation"],"metadata":{"id":"cSy7MLruFW7s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cB1tRigdl_Ru"},"outputs":[],"source":["##################\n","### Problem 3(c): Train VAE with analytical KL\n","epochs = 20\n","\n","hidden_dims = [128, 32, 16, 4]\n","assert hidden_dims[-1] == 4, \"always use 4 as the latent dimension for generating a 2D image grid during evaluation\"\n","\n","image_shape = MNIST_dataset[0][0].shape\n","input_dim = torch.prod(torch.tensor(image_shape)).item()\n","print(\"input_dim: \", input_dim)\n","\n","vae_kl_wo_e = VAE(input_dim, hidden_dims).to(device)\n","print(vae_kl_wo_e)\n","\n","optimizer_vae_kl_wo_e = torch.optim.Adam(vae_kl_wo_e.parameters(),\n","                                lr = 1e-4,\n","                                weight_decay = 1e-8)\n","\n","log_vae_kl_wo_e = train(MNIST_loader, vae_kl_wo_e, lambda model, x: loss_func(model, x, reg_func=loss_KL_wo_E, coeff=1e-3), optimizer_vae_kl_wo_e, epochs)\n","##################\n"]},{"cell_type":"markdown","source":["## g. Evaluation"],"metadata":{"id":"hhctuyLnIJEg"}},{"cell_type":"code","source":["##################\n","### Problem 3(c): Evaluate VAE with analytical KL\n","eval(vae_kl_wo_e)\n","plot_latent_images(vae_kl_wo_e, n=8)\n","##################\n"],"metadata":{"id":"zvaKlqDjIJKv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAi2wzhSmFW8"},"source":["# **3. Torus**\n","\n","## a. Data Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tw5NGBWLmLz-"},"outputs":[],"source":["def generate_torus_point_cloud(R, r, num_points=1000, seed=1234):\n","    \"\"\"\n","    Parameters:\n","    - R: Major radius of the torus (distance from the center of the tube to the center of the torus).\n","    - r: Minor radius of the torus (radius of the tube).\n","    - num_points: Number of points to sample in the point cloud.\n","\n","    Returns:\n","    - x, y, z: Arrays containing the x, y, and z coordinates of the sampled points.\n","    \"\"\"\n","    np.random.seed(seed)\n","    u = np.random.uniform(0, 2 * np.pi, num_points)\n","    np.random.seed(seed+1)\n","    v = np.random.uniform(0, 2 * np.pi, num_points)\n","\n","    x = (R + r * np.cos(v)) * np.cos(u)\n","    y = (R + r * np.cos(v)) * np.sin(u)\n","    z = r * np.sin(v)\n","\n","    points = np.vstack((x, y, z)).T\n","\n","    return points\n","\n","def plot_torus_point_cloud(x, y, z, ax, color='b', name='Training Data'):\n","    \"\"\"\n","    Plots the 3D point cloud of a torus.\n","    \"\"\"\n","    ax.scatter(x, y, z, c=color, marker='o', s=5)\n","\n","    # Set equal scaling for all axes\n","    max_range = np.array([x.max()-x.min(), y.max()-y.min(), z.max()-z.min()]).max() / 2.0\n","\n","    mid_x = (x.max() + x.min()) * 0.5\n","    mid_y = (y.max() + y.min()) * 0.5\n","    mid_z = (z.max() + z.min()) * 0.5\n","\n","    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n","    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n","    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n","\n","    ax.set_xlabel('X')\n","    ax.set_ylabel('Y')\n","    ax.set_zlabel('Z')\n","    ax.set_title(name)\n","    return ax\n","\n","class TorusPointCloudDataset(torch.utils.data.Dataset):\n","    def __init__(self, R, r, num_points=1000):\n","        \"\"\"\n","        Args:\n","            R (float): Major radius of the torus.\n","            r (float): Minor radius of the torus.\n","            num_points (int): Number of points to generate.\n","        \"\"\"\n","        points = generate_torus_point_cloud(R, r, num_points)\n","        self.points = torch.tensor(points, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.points)\n","\n","    def __getitem__(self, idx):\n","        return self.points[idx], 0 # dummy label\n","\n","R = 1.0\n","r = 0.5\n","num_points = 3000\n","\n","torus_pc_dataset = TorusPointCloudDataset(R, r, num_points)\n","torus_pc_dataloader = torch.utils.data.DataLoader(torus_pc_dataset, batch_size=3000, shuffle=True)\n","\n","\n","fig = plt.figure(figsize=(10, 7))\n","ax = fig.add_subplot(111, projection='3d')\n","plot_torus_point_cloud(torus_pc_dataset.points[:, 0], torus_pc_dataset.points[:, 1], torus_pc_dataset.points[:, 2], ax)\n","plt.show()\n"]},{"cell_type":"markdown","source":["## b. Network Architecture"],"metadata":{"id":"4Vp6KMp6tSlD"}},{"cell_type":"code","source":["class PositionalEncoding3D(torch.nn.Module):\n","    def __init__(self, num_frequencies=10):\n","        \"\"\"\n","        Initializes the positional encoding for 3D coordinates.\n","\n","        Args:\n","            num_frequencies (int): The number of different frequencies to use for encoding.\n","        \"\"\"\n","        super().__init__()\n","        self.num_frequencies = num_frequencies\n","        self.frequencies = 2 ** torch.arange(num_frequencies, dtype=torch.float32)\n","\n","    def forward(self, points):\n","        \"\"\"\n","        Applies positional encoding to the 3D points.\n","\n","        Args:\n","            points (torch.Tensor): N x 3 tensor of 3D coordinates.\n","\n","        Returns:\n","            torch.Tensor: N x (6*num_frequencies) tensor of encoded coordinates.\n","        \"\"\"\n","        encoded_points = []\n","        for i in range(points.shape[1]):  # For each dimension (x, y, z)\n","            for freq in self.frequencies:\n","                encoded_points.append(torch.sin(freq * points[:, i:i+1]))\n","                encoded_points.append(torch.cos(freq * points[:, i:i+1]))\n","        return torch.cat(encoded_points, dim=-1)\n","\n","###############\n","### Problem 4(c): Create your own VAE\n","###############\n","\n","class PointVAE(torch.nn.Module):\n","    def __init__(self, hidden_dims):\n","        super().__init__()\n","\n","        self.pos_enc = PositionalEncoding3D()\n","        #############\n","        ### Problem 4(c): Create your own VAE\n","        self.vae = VAE(input_dim=self.pos_enc.num_frequencies * 6, hidden_dims=hidden_dims, decode_dim=3, use_sigmoid=False)\n","        #############\n","\n","    def forward(self, x):\n","        emb = self.pos_enc(x)\n","        return self.vae(emb)\n"],"metadata":{"id":"gtdBrXVRfkb8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## c. Training"],"metadata":{"id":"Ru-luNDOtZ-l"}},{"cell_type":"code","source":["#############\n","### Problem 4(a): Train VAE on torus data\n","epochs = 1000\n","\n","hidden_dims = [32, 16, 8] # -> 2/3 dim\n","\n","point_vae = PointVAE(hidden_dims).to(device)\n","print(point_vae)\n","\n","optimizer_point_vae = torch.optim.Adam(point_vae.parameters(),\n","                                lr = 1e-3,\n","                                weight_decay = 1e-8)\n","\n","log_point_vae = train(torus_pc_dataloader, point_vae, lambda model, x: loss_func(model, x, reg_func=loss_KL_wo_E, coeff=0.0), optimizer_point_vae, epochs)\n","#############\n"],"metadata":{"id":"8_hRaXVMJV5v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## d. Evaluation on Reconstruction"],"metadata":{"id":"3WB-tn0ztcyD"}},{"cell_type":"code","source":["#############\n","### Problem 4(a): Evaluation on reconstruction\n","with torch.no_grad():\n","  output = point_vae(torus_pc_dataset.points.to(device))\n","  decoded_pc = output['imgs'].cpu().numpy()\n","\n","fig = plt.figure(figsize=(10, 7))\n","ax = fig.add_subplot(111, projection='3d')\n","plot_torus_point_cloud(decoded_pc[:, 0], decoded_pc[:, 1], decoded_pc[:, 2], ax, name=\"Decoded Data\")\n","#############\n"],"metadata":{"id":"a_LnyC9RLFUU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## e. Evaluation on Interpolation"],"metadata":{"id":"ZAti32efthmw"}},{"cell_type":"code","source":["#############\n","### Problem 4(v): Evaluation on linear interpolation\n","z0 = point_vae(torch.tensor([[0.0, 1.0, 0.]]).to(device))['z']\n","z1 = point_vae(torch.tensor([[0.0, -1.0, 0.]]).to(device))['z']\n","\n","print(hidden_dims[-1])\n","num_steps = 100\n","\n","weights = torch.linspace(0, 1, num_steps).view(-1, 1).to(device)\n","latent_vecs = weights * z0 + (1 - weights) * z1\n","\n","with torch.no_grad():\n","    outputs = point_vae.vae.decode(torch.tensor(latent_vecs).to(device))\n","\n","lin_traj = outputs.cpu().numpy()\n","\n","fig = plt.figure(figsize=(10, 7))\n","ax = fig.add_subplot(111, projection='3d')\n","plot_torus_point_cloud(lin_traj[:, 0], lin_traj[:, 1], lin_traj[:, 2], ax, color='r', name=\"Decoded Data\")\n","plot_torus_point_cloud(decoded_pc[:, 0], decoded_pc[:, 1], decoded_pc[:, 2], ax, name=\"Decoded Data\")\n","plt.show()\n","#############\n"],"metadata":{"id":"UugxXVquMi9q"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyN4u0qEeKSBY6QK1ybX54fX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}